{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def get_logger(name: str):\n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:  # Prevents duplicate handlers\n",
    "        logger.setLevel(logging.DEBUG)  # Set the logger level to DEBUG\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(logging.INFO)  # Set the handler level to INFO\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "        )  # Define the log message format\n",
    "        ch.setFormatter(formatter)\n",
    "        logger.addHandler(ch)\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_ROUTER_API_KEY = os.getenv(\"OPEN_ROUTER_API_KEY\")\n",
    "\n",
    "DAPPIER_API_KEY = os.getenv(\"DAPPIER_API_KEY\")\n",
    "\n",
    "AGENTOPS_API_KEY = os.getenv(\"AGENTOPS_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.toolkits import DappierToolkit, FunctionTool\n",
    "\n",
    "from utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "class WeatherToolWrapper:\n",
    "    def __init__(self):\n",
    "        self.toolkit = DappierToolkit()\n",
    "        logger.info(\"Weather Tool initialized\")\n",
    "\n",
    "    def get_tool(self):\n",
    "        return FunctionTool(self.search_weather)\n",
    "\n",
    "    def search_weather(self, query: str, city: str):\n",
    "        full_query = f\"{query} in {city}\"\n",
    "        logger.debug(\"WeatherTool query: %s\", full_query)\n",
    "        try:\n",
    "            response = self.toolkit.search_real_time_data(query=query)\n",
    "            logger.debug(\"WeatherTool response: %s\", response)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(\"WeatherTool error: %s\", str(e))\n",
    "            return \"Error retrieving weather data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.toolkits import DappierToolkit, FunctionTool\n",
    "from utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "class TrafficToolWrapper:\n",
    "    def __init__(self):\n",
    "        self.toolkit = DappierToolkit()\n",
    "        logger.info(\"Traffic Tool initialized\")\n",
    "    \n",
    "    def get_tool(self):\n",
    "        return FunctionTool(self.search_traffic)\n",
    "\n",
    "    def search_traffic(self, query: str, city: str):\n",
    "        full_query = f\"{query} in {city}\"\n",
    "        logger.debug(\"TrafficTool query: %s\", full_query)\n",
    "        try:\n",
    "            response = self.toolkit.search_real_time_data(query=full_query)\n",
    "            logger.debug(\"TrafficTool response: %s\", response)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(\"TrafficTool error: %s\", str(e))\n",
    "            return \"Error retrieving traffic data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: Could not record event - no sessions detected. Create a session by calling agentops.start_session()\n",
      "2025-03-06 04:21:31,171 - __main__ - INFO - Traffic Tool initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 04:21:31,171 - __main__ - INFO - Traffic Tool initialized\n",
      "2025-03-06 04:21:31,178 - camel.agents.chat_agent - WARNING - Overriding the configured tools in `BaseModelBackend` with the tools from `ChatAgent`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parthshr370/anaconda3/envs/agents/lib/python3.11/site-packages/camel/toolkits/function_tool.py:427: UserWarning: Function description is missing for \n",
      "                          search_traffic. This may \n",
      "                          affect the quality of tool calling.\n",
      "  warnings.warn(f\"\"\"Function description is missing for\n",
      "/home/parthshr370/anaconda3/envs/agents/lib/python3.11/site-packages/camel/toolkits/function_tool.py:448: UserWarning: Parameter description is missing for \n",
      "                            {'type': 'string'}. This may affect the quality of tool \n",
      "                            calling.\n",
      "  warnings.warn(f\"\"\"Parameter description is missing for\n",
      "2025-03-06 04:21:34,508 - __main__ - INFO - TrafficAgent response: msgs=[BaseMessage(role_name='Traffic Agent', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={}, content='', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)] terminated=False info={'id': 'gen-1741215092-QieXsJygzk5pB1mslfk1', 'usage': {'completion_tokens': 0, 'prompt_tokens': 299, 'total_tokens': 299, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'termination_reasons': ['stop'], 'num_tokens': 285, 'tool_calls': [], 'external_tool_request': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 04:21:34,508 - __main__ - INFO - TrafficAgent response: msgs=[BaseMessage(role_name='Traffic Agent', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={}, content='', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)] terminated=False info={'id': 'gen-1741215092-QieXsJygzk5pB1mslfk1', 'usage': {'completion_tokens': 0, 'prompt_tokens': 299, 'total_tokens': 299, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'termination_reasons': ['stop'], 'num_tokens': 285, 'tool_calls': [], 'external_tool_request': None}\n",
      "{'traffic_status': ChatAgentResponse(msgs=[BaseMessage(role_name='Traffic Agent', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={}, content='', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)], terminated=False, info={'id': 'gen-1741215092-QieXsJygzk5pB1mslfk1', 'usage': {'completion_tokens': 0, 'prompt_tokens': 299, 'total_tokens': 299, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'termination_reasons': ['stop'], 'num_tokens': 285, 'tool_calls': [], 'external_tool_request': None})}\n"
     ]
    }
   ],
   "source": [
    "# Test TrafficAgent\n",
    "traffic_agent = TrafficAgent(city)\n",
    "print(traffic_agent.get_traffic_status())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tool = TrafficToolWrapper()\\nresult = tool.search_traffic(\"traffic\", \"New York\")\\nprint(result)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tool = TrafficToolWrapper()\n",
    "result = tool.search_traffic(\"traffic\", \"New York\")\n",
    "print(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_city_data(citizen_data, traffic_data, env_data):\n",
    "    # Combine data from all agents into a city dashboard summary.\n",
    "    dashboard = \"=== Smart City Dashboard ===\\n\\n\"\n",
    "    dashboard += (\n",
    "        \"Citizen Feedback:\\n\" + citizen_data.get(\"citizen_feedback\", \"No data\") + \"\\n\\n\"\n",
    "    )\n",
    "\n",
    "    dashboard += (\n",
    "        \"Traffic Status:\\n\" + traffic_data.get(\"traffic_status\", \"No data\") + \"\\n\\n\"\n",
    "    )\n",
    "    dashboard += (\n",
    "        \"Environment Update:\\n\" + env_data.get(\"environment_update\", \"No data\") + \"\\n\"\n",
    "    )\n",
    "    return dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.agents.chat_agent import ChatAgent\n",
    "from camel.messages.base import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType\n",
    "from config import OPEN_ROUTER_API_KEY\n",
    "from tools.traffic_tool import TrafficToolWrapper\n",
    "from utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "class TrafficAgent:\n",
    "    def __init__(self, city):\n",
    "        self.city = city\n",
    "        self.model = ModelFactory.create(\n",
    "            model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n",
    "            api_key=OPEN_ROUTER_API_KEY,\n",
    "            model_type=\"google/gemini-2.0-flash-001\",\n",
    "            url=\"https://openrouter.ai/api/v1\",\n",
    "            model_config_dict={\"temperature\": 0.4, \"max_tokens\": 4096},\n",
    "        )\n",
    "\n",
    "        sys_msg = BaseMessage.make_assistant_message(\n",
    "            role_name=\"Traffic Agent\",\n",
    "            content=f\"You analyze current traffic conditions and congestion in the city {self.city}.\",\n",
    "        )\n",
    "\n",
    "        self.traffic_tool = TrafficToolWrapper()\n",
    "        self.agent = ChatAgent(\n",
    "            system_message=sys_msg,\n",
    "            model=self.model,\n",
    "            tools=[self.traffic_tool.get_tool()],\n",
    "        )\n",
    "\n",
    "    def get_traffic_status(self):\n",
    "        prompt = f\"What is the current traffic congestion status in {self.city}?\"\n",
    "        response = self.agent.step(prompt)\n",
    "        logger.info(\"TrafficAgent response: %s\", response)\n",
    "        return {\"traffic_status\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.agents.chat_agent import ChatAgent\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.messages.base import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "\n",
    "from config import OPEN_ROUTER_API_KEY\n",
    "from tools.weather_tool import WeatherToolWrapper\n",
    "from utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "class EnvironmentAgent:\n",
    "    def __init__(self, city):\n",
    "        self.city = city\n",
    "        self.model = ModelFactory.create(\n",
    "            model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n",
    "            api_key=OPEN_ROUTER_API_KEY,\n",
    "            model_type=\"google/gemini-2.0-flash-001\",\n",
    "            url=\"https://openrouter.ai/api/v1\",\n",
    "            model_config_dict={\"temperature\": 0.4, \"max_tokens\": 4096},\n",
    "        )\n",
    "\n",
    "        sys_msg = BaseMessage.make_assistant_message(\n",
    "            role_name=\"Environment Agent\",\n",
    "            content=f\"You provide real-time weather and environmental updates for {self.city}.\",\n",
    "        )\n",
    "\n",
    "        self.weather_tool = WeatherToolWrapper()\n",
    "        self.agent = ChatAgent(\n",
    "            system_message=sys_msg,\n",
    "            model=self.model,\n",
    "            tools=[self.weather_tool.get_tool()],\n",
    "        )\n",
    "        logger.info(\"Environment Agent initialized for city: %s\", self.city)\n",
    "\n",
    "    def get_environment_update(self):\n",
    "        prompt = f\"Provide the latest weather update and any notable environmental alerts for {self.city}.\"\n",
    "        response = self.agent.step(prompt)\n",
    "        logger.info(\"Environment update: %s\", response)\n",
    "        return {\"environment_update\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitizenAgent:\n",
    "    def __init__(self, city):\n",
    "        self.city = city\n",
    "        self.model = ModelFactory.create(\n",
    "            model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n",
    "            api_key=OPEN_ROUTER_API_KEY,\n",
    "            model_type=\"google/gemini-2.0-flash-001\",\n",
    "            url=\"https://openrouter.ai/api/v1\",\n",
    "            model_config_dict={\"temperature\": 0.4, \"max_tokens\": 4096},\n",
    "        )\n",
    "\n",
    "        sys_msg = BaseMessage.make_assistant_message(\n",
    "            role_name=\"Citizen Agent\",\n",
    "            content=f\"You simulate citizen feedback on urban issues (e.g., public events, safety, local services) in {self.city}.\",\n",
    "        )\n",
    "\n",
    "        self.agent = ChatAgent(system_message=sys_msg, model=self.model)\n",
    "        logger.info(\"Citizen Agent initialized for city: %s\", self.city)\n",
    "\n",
    "    def get_city_feedback(self):\n",
    "        prompt = f\"Provide recent citizen feedback on city services and public safety in {self.city}.\"\n",
    "        response = self.agent.step(prompt)\n",
    "        logger.info(\"City feedback: %s\", response)\n",
    "        return {\"citizen_feedback\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"Ney York\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: Could not record event - no sessions detected. Create a session by calling agentops.start_session()\n",
      "2025-03-06 04:22:05,605 - tools.weather_tool - INFO - Weather Tool initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 04:22:05,605 - tools.weather_tool - INFO - Weather Tool initialized\n",
      "2025-03-06 04:22:05,608 - camel.agents.chat_agent - WARNING - Overriding the configured tools in `BaseModelBackend` with the tools from `ChatAgent`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parthshr370/anaconda3/envs/agents/lib/python3.11/site-packages/camel/toolkits/function_tool.py:427: UserWarning: Function description is missing for \n",
      "                          search_weather. This may \n",
      "                          affect the quality of tool calling.\n",
      "  warnings.warn(f\"\"\"Function description is missing for\n",
      "2025-03-06 04:22:05,610 - __main__ - INFO - Environment Agent initialized for city: Ney York\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 04:22:05,610 - __main__ - INFO - Environment Agent initialized for city: Ney York\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 04:22:11,638 - __main__ - INFO - Environment update: msgs=[BaseMessage(role_name='Environment Agent', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={}, content='', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)] terminated=False info={'id': 'gen-1741215128-U7yOpfJKfWXVYYKDk8sr', 'usage': {'completion_tokens': 0, 'prompt_tokens': 302, 'total_tokens': 302, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'termination_reasons': ['stop'], 'num_tokens': 285, 'tool_calls': [], 'external_tool_request': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 04:22:11,638 - __main__ - INFO - Environment update: msgs=[BaseMessage(role_name='Environment Agent', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={}, content='', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)] terminated=False info={'id': 'gen-1741215128-U7yOpfJKfWXVYYKDk8sr', 'usage': {'completion_tokens': 0, 'prompt_tokens': 302, 'total_tokens': 302, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'termination_reasons': ['stop'], 'num_tokens': 285, 'tool_calls': [], 'external_tool_request': None}\n",
      "{'environment_update': ChatAgentResponse(msgs=[BaseMessage(role_name='Environment Agent', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={}, content='', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)], terminated=False, info={'id': 'gen-1741215128-U7yOpfJKfWXVYYKDk8sr', 'usage': {'completion_tokens': 0, 'prompt_tokens': 302, 'total_tokens': 302, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'termination_reasons': ['stop'], 'num_tokens': 285, 'tool_calls': [], 'external_tool_request': None})}\n"
     ]
    }
   ],
   "source": [
    "environment_agent = EnvironmentAgent(city)\n",
    "print(environment_agent.get_environment_update())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_agentops_agent_id', '_agentops_agent_name', '_extract_tool_call', '_generate_tool_prompt', '_handle_step', '_initialize_tools', '_inject_tool_prompt', '_is_standard_response', '_log_final_output', '_parse_tool_response', '_safe_json_loads', '_safe_model_dump', '_step_get_info', '_step_model_response', '_step_token_exceed', '_step_tool_call', '_step_tool_call_and_update', '_step_tool_call_and_update_async', '_structure_output_with_function', '_system_message', 'add_model_scheduling_strategy', 'add_tool', 'agentops_agent_id', 'agentops_agent_name', 'all_tools', 'external_tool_names', 'external_tools', 'get_info', 'get_usage_dict', 'handle_batch_response', 'handle_stream_response', 'init_messages', 'is_tools_added', 'list_tools', 'memory', 'model_backend', 'model_token_limit', 'model_type', 'orig_sys_message', 'output_language', 'record_message', 'remove_tool', 'reset', 'response_terminators', 'role_name', 'role_type', 'set_output_language', 'single_iteration', 'step', 'step_async', 'step_tool_call_async', 'system_message', 'terminated', 'tool_dict', 'tool_prompt_added', 'tools', 'update_memory']\n"
     ]
    }
   ],
   "source": [
    "print(dir(citizen_agent.agent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: AgentOps has already been initialized. If you are trying to start a session, call agentops.start_session() instead.\n",
      "2025-03-06 03:57:19,704 - __main__ - INFO - Starting City Emulator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 03:57:19,704 - __main__ - INFO - Starting City Emulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 03:57:21,919 - __main__ - INFO - Instantiating agents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 03:57:21,919 - __main__ - INFO - Instantiating agents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 03:57:22,688 - agents.citizen_agent - INFO - Citizen Agent initialized for city: nyc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 03:57:22,688 - agents.citizen_agent - INFO - Citizen Agent initialized for city: nyc\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrafficAgent.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgentOps session ended successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstantiating agents...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m citizen_agent \u001b[38;5;241m=\u001b[39m CitizenAgent(city)\n\u001b[0;32m---> 18\u001b[0m traffic_agent \u001b[38;5;241m=\u001b[39m \u001b[43mTrafficAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m environment_agent \u001b[38;5;241m=\u001b[39m EnvironmentAgent(city)\n\u001b[1;32m     21\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollecting citizen feedback...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: TrafficAgent.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import agentops\n",
    "from utils.logger import get_logger\n",
    "from agents.citizen_agent import CitizenAgent\n",
    "from agents.traffic_agent import TrafficAgent\n",
    "from agents.environment_agent import EnvironmentAgent\n",
    "from tools.data_aggregator import aggregate_city_data\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "def main():\n",
    "    agentops.init(default_tags=[\"City Emulator\"])\n",
    "    logger.info(\"Starting City Emulator\")\n",
    "    \n",
    "    city = input(\"Enter the city for which you want to retrieve data (default: NYC): \") or \"NYC\"\n",
    "    \n",
    "    logger.info(\"Instantiating agents...\")\n",
    "    citizen_agent = CitizenAgent(city)\n",
    "    traffic_agent = TrafficAgent(city)\n",
    "    environment_agent = EnvironmentAgent(city)\n",
    "    \n",
    "    logger.info(\"Collecting citizen feedback...\")\n",
    "    citizen_data = citizen_agent.get_city_feedback()\n",
    "\n",
    "    logger.info(\"Collecting traffic data...\")\n",
    "    traffic_data = traffic_agent.get_traffic_status()\n",
    "\n",
    "    logger.info(\"Collecting environmental updates...\")\n",
    "    env_data = environment_agent.get_environment_update()\n",
    "\n",
    "    logger.info(\"Aggregating city data...\")\n",
    "    dashboard = aggregate_city_data(citizen_data, traffic_data, env_data)\n",
    "    print(\"\\n--- City Dashboard ---\\n\")\n",
    "    print(dashboard)\n",
    "\n",
    "    agentops.end_session(\"Success\")\n",
    "    logger.info(\"AgentOps session ended successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ModelType.GPT_4O_MINI: 'gpt-4o-mini'>, <ModelType.GPT_3_5_TURBO: 'gpt-3.5-turbo'>, <ModelType.GPT_4: 'gpt-4'>, <ModelType.GPT_4_TURBO: 'gpt-4-turbo'>, <ModelType.GPT_4O: 'gpt-4o'>, <ModelType.O1: 'o1'>, <ModelType.O1_PREVIEW: 'o1-preview'>, <ModelType.O1_MINI: 'o1-mini'>, <ModelType.O3_MINI: 'o3-mini'>, <ModelType.GLM_4: 'glm-4'>, <ModelType.GLM_4V: 'glm-4v'>, <ModelType.GLM_4V_FLASH: 'glm-4v-flash'>, <ModelType.GLM_4V_PLUS_0111: 'glm-4v-plus-0111'>, <ModelType.GLM_4_PLUS: 'glm-4-plus'>, <ModelType.GLM_4_AIR: 'glm-4-air'>, <ModelType.GLM_4_AIR_0111: 'glm-4-air-0111'>, <ModelType.GLM_4_AIRX: 'glm-4-airx'>, <ModelType.GLM_4_LONG: 'glm-4-long'>, <ModelType.GLM_4_FLASHX: 'glm-4-flashx'>, <ModelType.GLM_4_FLASH: 'glm-4-flash'>, <ModelType.GLM_ZERO_PREVIEW: 'glm-zero-preview'>, <ModelType.GLM_3_TURBO: 'glm-3-turbo'>, <ModelType.GROQ_LLAMA_3_1_8B: 'llama-3.1-8b-instant'>, <ModelType.GROQ_LLAMA_3_3_70B: 'llama-3.3-70b-versatile'>, <ModelType.GROQ_LLAMA_3_3_70B_PREVIEW: 'llama-3.3-70b-specdec'>, <ModelType.GROQ_LLAMA_3_8B: 'llama3-8b-8192'>, <ModelType.GROQ_LLAMA_3_70B: 'llama3-70b-8192'>, <ModelType.GROQ_MIXTRAL_8_7B: 'mixtral-8x7b-32768'>, <ModelType.GROQ_GEMMA_2_9B_IT: 'gemma2-9b-it'>, <ModelType.TOGETHER_LLAMA_3_1_8B: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'>, <ModelType.TOGETHER_LLAMA_3_1_70B: 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo'>, <ModelType.TOGETHER_LLAMA_3_1_405B: 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'>, <ModelType.TOGETHER_LLAMA_3_3_70B: 'meta-llama/Llama-3.3-70B-Instruct-Turbo'>, <ModelType.AIML_MIXTRAL_8X7B: 'mistralai/Mixtral-8x7B-Instruct-v0.1'>, <ModelType.AIML_MISTRAL_7B_INSTRUCT: 'mistralai/Mistral-7B-Instruct-v0.1'>, <ModelType.SAMBA_LLAMA_3_1_8B: 'Meta-Llama-3.1-8B-Instruct'>, <ModelType.SAMBA_LLAMA_3_1_70B: 'Meta-Llama-3.1-70B-Instruct'>, <ModelType.SAMBA_LLAMA_3_1_405B: 'Meta-Llama-3.1-405B-Instruct'>, <ModelType.SGLANG_LLAMA_3_1_8B: 'meta-llama/Meta-Llama-3.1-8B-Instruct'>, <ModelType.SGLANG_LLAMA_3_1_70B: 'meta-llama/Meta-Llama-3.1-70B-Instruct'>, <ModelType.SGLANG_LLAMA_3_1_405B: 'meta-llama/Meta-Llama-3.1-405B-Instruct'>, <ModelType.SGLANG_LLAMA_3_2_1B: 'meta-llama/Llama-3.2-1B-Instruct'>, <ModelType.SGLANG_MIXTRAL_NEMO: 'mistralai/Mistral-Nemo-Instruct-2407'>, <ModelType.SGLANG_MISTRAL_7B: 'mistralai/Mistral-7B-Instruct-v0.3'>, <ModelType.SILICONFLOW_QWEN2_5_7B_INSTRUCT: 'Qwen/Qwen2.5-7B-Instruct'>, <ModelType.SILICONFLOW_QWEN2_5_32B_INSTRUCT: 'Qwen/Qwen2.5-32B-Instruct'>, <ModelType.SILICONFLOW_QWEN2_5_72B_INSTRUCT: 'Qwen/Qwen2.5-72B-Instruct'>, <ModelType.STUB: 'stub'>, <ModelType.CLAUDE_2_1: 'claude-2.1'>, <ModelType.CLAUDE_2_0: 'claude-2.0'>, <ModelType.CLAUDE_INSTANT_1_2: 'claude-instant-1.2'>, <ModelType.CLAUDE_3_OPUS: 'claude-3-opus-latest'>, <ModelType.CLAUDE_3_SONNET: 'claude-3-sonnet-20240229'>, <ModelType.CLAUDE_3_HAIKU: 'claude-3-haiku-20240307'>, <ModelType.CLAUDE_3_5_SONNET: 'claude-3-5-sonnet-latest'>, <ModelType.CLAUDE_3_5_HAIKU: 'claude-3-5-haiku-latest'>, <ModelType.NVIDIA_NEMOTRON_340B_INSTRUCT: 'nvidia/nemotron-4-340b-instruct'>, <ModelType.NVIDIA_NEMOTRON_340B_REWARD: 'nvidia/nemotron-4-340b-reward'>, <ModelType.NVIDIA_YI_LARGE: '01-ai/yi-large'>, <ModelType.NVIDIA_MISTRAL_LARGE: 'mistralai/mistral-large'>, <ModelType.NVIDIA_MIXTRAL_8X7B: 'mistralai/mixtral-8x7b-instruct'>, <ModelType.NVIDIA_LLAMA3_70B: 'meta/llama3-70b'>, <ModelType.NVIDIA_LLAMA3_1_8B_INSTRUCT: 'meta/llama-3.1-8b-instruct'>, <ModelType.NVIDIA_LLAMA3_1_70B_INSTRUCT: 'meta/llama-3.1-70b-instruct'>, <ModelType.NVIDIA_LLAMA3_1_405B_INSTRUCT: 'meta/llama-3.1-405b-instruct'>, <ModelType.NVIDIA_LLAMA3_2_1B_INSTRUCT: 'meta/llama-3.2-1b-instruct'>, <ModelType.NVIDIA_LLAMA3_2_3B_INSTRUCT: 'meta/llama-3.2-3b-instruct'>, <ModelType.NVIDIA_LLAMA3_3_70B_INSTRUCT: 'meta/llama-3.3-70b-instruct'>, <ModelType.GEMINI_2_0_FLASH: 'gemini-2.0-flash-exp'>, <ModelType.GEMINI_2_0_FLASH_THINKING: 'gemini-2.0-flash-thinking-exp'>, <ModelType.GEMINI_2_0_PRO_EXP: 'gemini-2.0-pro-exp-02-05'>, <ModelType.GEMINI_2_0_FLASH_LITE_PREVIEW: 'gemini-2.0-flash-lite-preview-02-05'>, <ModelType.GEMINI_1_5_FLASH: 'gemini-1.5-flash'>, <ModelType.GEMINI_1_5_PRO: 'gemini-1.5-pro'>, <ModelType.MISTRAL_3B: 'ministral-3b-latest'>, <ModelType.MISTRAL_7B: 'open-mistral-7b'>, <ModelType.MISTRAL_8B: 'ministral-8b-latest'>, <ModelType.MISTRAL_CODESTRAL: 'codestral-latest'>, <ModelType.MISTRAL_CODESTRAL_MAMBA: 'open-codestral-mamba'>, <ModelType.MISTRAL_LARGE: 'mistral-large-latest'>, <ModelType.MISTRAL_MIXTRAL_8x7B: 'open-mixtral-8x7b'>, <ModelType.MISTRAL_MIXTRAL_8x22B: 'open-mixtral-8x22b'>, <ModelType.MISTRAL_NEMO: 'open-mistral-nemo'>, <ModelType.MISTRAL_PIXTRAL_12B: 'pixtral-12b-2409'>, <ModelType.REKA_CORE: 'reka-core'>, <ModelType.REKA_FLASH: 'reka-flash'>, <ModelType.REKA_EDGE: 'reka-edge'>, <ModelType.COHERE_COMMAND_R_PLUS: 'command-r-plus'>, <ModelType.COHERE_COMMAND_R: 'command-r'>, <ModelType.COHERE_COMMAND_LIGHT: 'command-light'>, <ModelType.COHERE_COMMAND: 'command'>, <ModelType.COHERE_COMMAND_NIGHTLY: 'command-nightly'>, <ModelType.QWEN_MAX: 'qwen-max'>, <ModelType.QWEN_PLUS: 'qwen-plus'>, <ModelType.QWEN_TURBO: 'qwen-turbo'>, <ModelType.QWEN_LONG: 'qwen-long'>, <ModelType.QWEN_VL_MAX: 'qwen-vl-max'>, <ModelType.QWEN_VL_PLUS: 'qwen-vl-plus'>, <ModelType.QWEN_MATH_PLUS: 'qwen-math-plus'>, <ModelType.QWEN_MATH_TURBO: 'qwen-math-turbo'>, <ModelType.QWEN_CODER_TURBO: 'qwen-coder-turbo'>, <ModelType.QWEN_2_5_CODER_32B: 'qwen2.5-coder-32b-instruct'>, <ModelType.QWEN_2_5_VL_72B: 'qwen2.5-vl-72b-instruct'>, <ModelType.QWEN_2_5_72B: 'qwen2.5-72b-instruct'>, <ModelType.QWEN_2_5_32B: 'qwen2.5-32b-instruct'>, <ModelType.QWEN_2_5_14B: 'qwen2.5-14b-instruct'>, <ModelType.QWEN_QWQ_32B: 'qwq-32b-preview'>, <ModelType.QWEN_QVQ_72B: 'qvq-72b-preview'>, <ModelType.YI_LIGHTNING: 'yi-lightning'>, <ModelType.YI_LARGE: 'yi-large'>, <ModelType.YI_MEDIUM: 'yi-medium'>, <ModelType.YI_LARGE_TURBO: 'yi-large-turbo'>, <ModelType.YI_VISION: 'yi-vision'>, <ModelType.YI_MEDIUM_200K: 'yi-medium-200k'>, <ModelType.YI_SPARK: 'yi-spark'>, <ModelType.YI_LARGE_RAG: 'yi-large-rag'>, <ModelType.YI_LARGE_FC: 'yi-large-fc'>, <ModelType.DEEPSEEK_CHAT: 'deepseek-chat'>, <ModelType.DEEPSEEK_REASONER: 'deepseek-reasoner'>, <ModelType.INTERNLM3_LATEST: 'internlm3-latest'>, <ModelType.INTERNLM3_8B_INSTRUCT: 'internlm3-8b-instruct'>, <ModelType.INTERNLM2_5_LATEST: 'internlm2.5-latest'>, <ModelType.INTERNLM2_PRO_CHAT: 'internlm2-pro-chat'>, <ModelType.MOONSHOT_V1_8K: 'moonshot-v1-8k'>, <ModelType.MOONSHOT_V1_32K: 'moonshot-v1-32k'>, <ModelType.MOONSHOT_V1_128K: 'moonshot-v1-128k'>, <ModelType.SILICONFLOW_DEEPSEEK_V2_5: 'deepseek-ai/DeepSeek-V2.5'>, <ModelType.SILICONFLOW_DEEPSEEK_V3: 'deepseek-ai/DeepSeek-V3'>, <ModelType.SILICONFLOW_INTERN_LM2_5_20B_CHAT: 'internlm/internlm2_5-20b-chat'>, <ModelType.SILICONFLOW_INTERN_LM2_5_7B_CHAT: 'internlm/internlm2_5-7b-chat'>, <ModelType.SILICONFLOW_PRO_INTERN_LM2_5_7B_CHAT: 'Pro/internlm/internlm2_5-7b-chat'>, <ModelType.SILICONFLOW_QWEN2_5_14B_INSTRUCT: 'Qwen/Qwen2.5-14B-Instruct'>, <ModelType.SILICONFLOW_PRO_QWEN2_5_7B_INSTRUCT: 'Pro/Qwen/Qwen2.5-7B-Instruct'>, <ModelType.SILICONFLOW_THUDM_GLM_4_9B_CHAT: 'THUDM/glm-4-9b-chat'>, <ModelType.SILICONFLOW_PRO_THUDM_GLM_4_9B_CHAT: 'Pro/THUDM/glm-4-9b-chat'>]\n"
     ]
    }
   ],
   "source": [
    "from camel.types import ModelType\n",
    "print(list(ModelType))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
